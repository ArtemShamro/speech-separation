{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43a02d0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/atem/Data/HSE_videos/4_DLA/hw_2_SeppechSep/git_speech_separation\n"
     ]
    }
   ],
   "source": [
    "cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69d8e31a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-11-21 11:11:08,019][__main__][INFO] - Loading pretrained model from Hugging Face: areshx/source-sep@dttnet_low_freq\n",
      "[2025-11-21 11:11:08,019][__main__][INFO] - Downloading model from Hugging Face Hub: areshx/source-sep@dttnet_low_freq (model.pth)\n",
      "[2025-11-21 11:11:08,672][__main__][INFO] - Model weights successfully loaded from Hugging Face: areshx/source-sep@dttnet_low_freq\n",
      "[2025-11-21 11:11:08,673][__main__][INFO] - DTTNetModel(\n",
      "  (encoder): Encoder(\n",
      "    (init_conv): Conv2d(2, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (encoder_layers): ModuleList(\n",
      "      (0): EncoderBlock(\n",
      "        (tfc_tdf): TFC_TDF_Block(\n",
      "          (conv1): Sequential(\n",
      "            (0): Sequential(\n",
      "              (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "              (1): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "              (2): GELU(approximate='none')\n",
      "            )\n",
      "            (1): Sequential(\n",
      "              (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "              (1): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "              (2): GELU(approximate='none')\n",
      "            )\n",
      "            (2): Sequential(\n",
      "              (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "              (1): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "              (2): GELU(approximate='none')\n",
      "            )\n",
      "          )\n",
      "          (fc): Sequential(\n",
      "            (0): Linear(in_features=513, out_features=256, bias=True)\n",
      "            (1): Linear(in_features=256, out_features=513, bias=True)\n",
      "          )\n",
      "          (conv2): Sequential(\n",
      "            (0): Sequential(\n",
      "              (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "              (1): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "              (2): GELU(approximate='none')\n",
      "            )\n",
      "            (1): Sequential(\n",
      "              (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "              (1): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "              (2): GELU(approximate='none')\n",
      "            )\n",
      "            (2): Sequential(\n",
      "              (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "              (1): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "              (2): GELU(approximate='none')\n",
      "            )\n",
      "          )\n",
      "          (skip_conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "        )\n",
      "        (downsampling): DownSamplingBlock(\n",
      "          (downsampling): Sequential(\n",
      "            (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "            (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "            (2): GELU(approximate='none')\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): EncoderBlock(\n",
      "        (tfc_tdf): TFC_TDF_Block(\n",
      "          (conv1): Sequential(\n",
      "            (0): Sequential(\n",
      "              (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "              (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "              (2): GELU(approximate='none')\n",
      "            )\n",
      "            (1): Sequential(\n",
      "              (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "              (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "              (2): GELU(approximate='none')\n",
      "            )\n",
      "            (2): Sequential(\n",
      "              (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "              (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "              (2): GELU(approximate='none')\n",
      "            )\n",
      "          )\n",
      "          (fc): Sequential(\n",
      "            (0): Linear(in_features=257, out_features=128, bias=True)\n",
      "            (1): Linear(in_features=128, out_features=257, bias=True)\n",
      "          )\n",
      "          (conv2): Sequential(\n",
      "            (0): Sequential(\n",
      "              (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "              (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "              (2): GELU(approximate='none')\n",
      "            )\n",
      "            (1): Sequential(\n",
      "              (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "              (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "              (2): GELU(approximate='none')\n",
      "            )\n",
      "            (2): Sequential(\n",
      "              (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "              (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "              (2): GELU(approximate='none')\n",
      "            )\n",
      "          )\n",
      "          (skip_conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "        )\n",
      "        (downsampling): DownSamplingBlock(\n",
      "          (downsampling): Sequential(\n",
      "            (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "            (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "            (2): GELU(approximate='none')\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (2): EncoderBlock(\n",
      "        (tfc_tdf): TFC_TDF_Block(\n",
      "          (conv1): Sequential(\n",
      "            (0): Sequential(\n",
      "              (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "              (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "              (2): GELU(approximate='none')\n",
      "            )\n",
      "            (1): Sequential(\n",
      "              (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "              (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "              (2): GELU(approximate='none')\n",
      "            )\n",
      "            (2): Sequential(\n",
      "              (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "              (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "              (2): GELU(approximate='none')\n",
      "            )\n",
      "          )\n",
      "          (fc): Sequential(\n",
      "            (0): Linear(in_features=129, out_features=64, bias=True)\n",
      "            (1): Linear(in_features=64, out_features=129, bias=True)\n",
      "          )\n",
      "          (conv2): Sequential(\n",
      "            (0): Sequential(\n",
      "              (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "              (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "              (2): GELU(approximate='none')\n",
      "            )\n",
      "            (1): Sequential(\n",
      "              (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "              (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "              (2): GELU(approximate='none')\n",
      "            )\n",
      "            (2): Sequential(\n",
      "              (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "              (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "              (2): GELU(approximate='none')\n",
      "            )\n",
      "          )\n",
      "          (skip_conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "        )\n",
      "        (downsampling): DownSamplingBlock(\n",
      "          (downsampling): Sequential(\n",
      "            (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "            (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "            (2): GELU(approximate='none')\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): Decoder(\n",
      "    (out_conv): Conv2d(32, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (decoder_layers): ModuleList(\n",
      "      (0): DecoderBlock(\n",
      "        (tfc_tdf): TFC_TDF_Block(\n",
      "          (conv1): Sequential(\n",
      "            (0): Sequential(\n",
      "              (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "              (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "              (2): GELU(approximate='none')\n",
      "            )\n",
      "            (1): Sequential(\n",
      "              (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "              (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "              (2): GELU(approximate='none')\n",
      "            )\n",
      "            (2): Sequential(\n",
      "              (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "              (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "              (2): GELU(approximate='none')\n",
      "            )\n",
      "          )\n",
      "          (fc): Sequential(\n",
      "            (0): Linear(in_features=129, out_features=64, bias=True)\n",
      "            (1): Linear(in_features=64, out_features=129, bias=True)\n",
      "          )\n",
      "          (conv2): Sequential(\n",
      "            (0): Sequential(\n",
      "              (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "              (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "              (2): GELU(approximate='none')\n",
      "            )\n",
      "            (1): Sequential(\n",
      "              (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "              (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "              (2): GELU(approximate='none')\n",
      "            )\n",
      "            (2): Sequential(\n",
      "              (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "              (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "              (2): GELU(approximate='none')\n",
      "            )\n",
      "          )\n",
      "          (skip_conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "        )\n",
      "        (upsampling): UpSamplingBlock(\n",
      "          (upsampling): Sequential(\n",
      "            (0): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "            (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "            (2): GELU(approximate='none')\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): DecoderBlock(\n",
      "        (tfc_tdf): TFC_TDF_Block(\n",
      "          (conv1): Sequential(\n",
      "            (0): Sequential(\n",
      "              (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "              (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "              (2): GELU(approximate='none')\n",
      "            )\n",
      "            (1): Sequential(\n",
      "              (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "              (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "              (2): GELU(approximate='none')\n",
      "            )\n",
      "            (2): Sequential(\n",
      "              (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "              (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "              (2): GELU(approximate='none')\n",
      "            )\n",
      "          )\n",
      "          (fc): Sequential(\n",
      "            (0): Linear(in_features=257, out_features=128, bias=True)\n",
      "            (1): Linear(in_features=128, out_features=257, bias=True)\n",
      "          )\n",
      "          (conv2): Sequential(\n",
      "            (0): Sequential(\n",
      "              (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "              (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "              (2): GELU(approximate='none')\n",
      "            )\n",
      "            (1): Sequential(\n",
      "              (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "              (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "              (2): GELU(approximate='none')\n",
      "            )\n",
      "            (2): Sequential(\n",
      "              (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "              (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "              (2): GELU(approximate='none')\n",
      "            )\n",
      "          )\n",
      "          (skip_conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "        )\n",
      "        (upsampling): UpSamplingBlock(\n",
      "          (upsampling): Sequential(\n",
      "            (0): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "            (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "            (2): GELU(approximate='none')\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (2): DecoderBlock(\n",
      "        (tfc_tdf): TFC_TDF_Block(\n",
      "          (conv1): Sequential(\n",
      "            (0): Sequential(\n",
      "              (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "              (1): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "              (2): GELU(approximate='none')\n",
      "            )\n",
      "            (1): Sequential(\n",
      "              (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "              (1): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "              (2): GELU(approximate='none')\n",
      "            )\n",
      "            (2): Sequential(\n",
      "              (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "              (1): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "              (2): GELU(approximate='none')\n",
      "            )\n",
      "          )\n",
      "          (fc): Sequential(\n",
      "            (0): Linear(in_features=513, out_features=256, bias=True)\n",
      "            (1): Linear(in_features=256, out_features=513, bias=True)\n",
      "          )\n",
      "          (conv2): Sequential(\n",
      "            (0): Sequential(\n",
      "              (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "              (1): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "              (2): GELU(approximate='none')\n",
      "            )\n",
      "            (1): Sequential(\n",
      "              (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "              (1): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "              (2): GELU(approximate='none')\n",
      "            )\n",
      "            (2): Sequential(\n",
      "              (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "              (1): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "              (2): GELU(approximate='none')\n",
      "            )\n",
      "          )\n",
      "          (skip_conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "        )\n",
      "        (upsampling): UpSamplingBlock(\n",
      "          (upsampling): Sequential(\n",
      "            (0): ConvTranspose2d(64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "            (1): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "            (2): GELU(approximate='none')\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (latent): LatentModule(\n",
      "    (tfc_tdf): TFC_TDF_Block(\n",
      "      (conv1): Sequential(\n",
      "        (0): Sequential(\n",
      "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "          (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "          (2): GELU(approximate='none')\n",
      "        )\n",
      "        (1): Sequential(\n",
      "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "          (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "          (2): GELU(approximate='none')\n",
      "        )\n",
      "        (2): Sequential(\n",
      "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "          (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "          (2): GELU(approximate='none')\n",
      "        )\n",
      "      )\n",
      "      (fc): Sequential(\n",
      "        (0): Linear(in_features=65, out_features=32, bias=True)\n",
      "        (1): Linear(in_features=32, out_features=65, bias=True)\n",
      "      )\n",
      "      (conv2): Sequential(\n",
      "        (0): Sequential(\n",
      "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "          (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "          (2): GELU(approximate='none')\n",
      "        )\n",
      "        (1): Sequential(\n",
      "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "          (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "          (2): GELU(approximate='none')\n",
      "        )\n",
      "        (2): Sequential(\n",
      "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "          (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "          (2): GELU(approximate='none')\n",
      "        )\n",
      "      )\n",
      "      (skip_conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    )\n",
      "    (idp_modules): ModuleList(\n",
      "      (0-3): 4 x IDPModule(\n",
      "        (tc_rnn): TC_FC_RNN(\n",
      "          (norm): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
      "          (blstm): LSTM(128, 256, batch_first=True, bidirectional=True)\n",
      "          (fc): Linear(in_features=512, out_features=128, bias=True)\n",
      "        )\n",
      "        (fc_rnn): TC_FC_RNN(\n",
      "          (norm): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
      "          (blstm): LSTM(128, 256, batch_first=True, bidirectional=True)\n",
      "          (fc): Linear(in_features=512, out_features=128, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "test:   0%|                                             | 0/157 [00:28<?, ?it/s]\n",
      "Error executing job with overrides: ['model=dttnet', 'model_loader.from_pretrained=areshx/source-sep@dttnet_low_freq']\n",
      "Traceback (most recent call last):\n",
      "  File \"/media/atem/Data/HSE_videos/4_DLA/hw_2_SeppechSep/git_speech_separation/inference.py\", line 71, in main\n",
      "    logs = inferencer.run_inference()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/atem/Data/HSE_videos/4_DLA/hw_2_SeppechSep/git_speech_separation/src/trainer/inferencer.py\", line 95, in run_inference\n",
      "    logs = self._inference_part(part, dataloader)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/atem/Data/HSE_videos/4_DLA/hw_2_SeppechSep/git_speech_separation/src/trainer/inferencer.py\", line 128, in _inference_part\n",
      "    batch = self.process_batch(\n",
      "            ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/atem/Data/HSE_videos/4_DLA/hw_2_SeppechSep/git_speech_separation/src/trainer/inferencer.py\", line 162, in process_batch\n",
      "    outputs = self.model(**batch)  # beam_search, llm_use\n",
      "              ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/atem/Data/HSE_videos/4_DLA/hw_2_SeppechSep/git_speech_separation/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/atem/Data/HSE_videos/4_DLA/hw_2_SeppechSep/git_speech_separation/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/atem/Data/HSE_videos/4_DLA/hw_2_SeppechSep/git_speech_separation/src/model/DTTNet/model_dttnet.py\", line 41, in forward\n",
      "    x, skip_results = self.encoder(spectrogram, phase)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/atem/Data/HSE_videos/4_DLA/hw_2_SeppechSep/git_speech_separation/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/atem/Data/HSE_videos/4_DLA/hw_2_SeppechSep/git_speech_separation/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/atem/Data/HSE_videos/4_DLA/hw_2_SeppechSep/git_speech_separation/src/model/DTTNet/modules/encoder.py\", line 30, in forward\n",
      "    x, skip = layer(x)\n",
      "              ^^^^^^^^\n",
      "  File \"/media/atem/Data/HSE_videos/4_DLA/hw_2_SeppechSep/git_speech_separation/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/atem/Data/HSE_videos/4_DLA/hw_2_SeppechSep/git_speech_separation/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/atem/Data/HSE_videos/4_DLA/hw_2_SeppechSep/git_speech_separation/src/model/DTTNet/modules/encoder.py\", line 44, in forward\n",
      "    skip = self.tfc_tdf(x)\n",
      "           ^^^^^^^^^^^^^^^\n",
      "  File \"/media/atem/Data/HSE_videos/4_DLA/hw_2_SeppechSep/git_speech_separation/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/atem/Data/HSE_videos/4_DLA/hw_2_SeppechSep/git_speech_separation/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/atem/Data/HSE_videos/4_DLA/hw_2_SeppechSep/git_speech_separation/src/model/DTTNet/blocks/block_tfc_tdf.py\", line 45, in forward\n",
      "    out = checkpoint(self.conv2, out)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/atem/Data/HSE_videos/4_DLA/hw_2_SeppechSep/git_speech_separation/.venv/lib/python3.12/site-packages/torch/_compile.py\", line 32, in inner\n",
      "    return disable_fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/atem/Data/HSE_videos/4_DLA/hw_2_SeppechSep/git_speech_separation/.venv/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py\", line 632, in _fn\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/atem/Data/HSE_videos/4_DLA/hw_2_SeppechSep/git_speech_separation/.venv/lib/python3.12/site-packages/torch/utils/checkpoint.py\", line 489, in checkpoint\n",
      "    return CheckpointFunction.apply(function, preserve, *args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/atem/Data/HSE_videos/4_DLA/hw_2_SeppechSep/git_speech_separation/.venv/lib/python3.12/site-packages/torch/autograd/function.py\", line 575, in apply\n",
      "    return super().apply(*args, **kwargs)  # type: ignore[misc]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/atem/Data/HSE_videos/4_DLA/hw_2_SeppechSep/git_speech_separation/.venv/lib/python3.12/site-packages/torch/utils/checkpoint.py\", line 264, in forward\n",
      "    outputs = run_function(*args)\n",
      "              ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/atem/Data/HSE_videos/4_DLA/hw_2_SeppechSep/git_speech_separation/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/atem/Data/HSE_videos/4_DLA/hw_2_SeppechSep/git_speech_separation/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/atem/Data/HSE_videos/4_DLA/hw_2_SeppechSep/git_speech_separation/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py\", line 250, in forward\n",
      "    input = module(input)\n",
      "            ^^^^^^^^^^^^^\n",
      "  File \"/media/atem/Data/HSE_videos/4_DLA/hw_2_SeppechSep/git_speech_separation/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/atem/Data/HSE_videos/4_DLA/hw_2_SeppechSep/git_speech_separation/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/atem/Data/HSE_videos/4_DLA/hw_2_SeppechSep/git_speech_separation/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py\", line 250, in forward\n",
      "    input = module(input)\n",
      "            ^^^^^^^^^^^^^\n",
      "  File \"/media/atem/Data/HSE_videos/4_DLA/hw_2_SeppechSep/git_speech_separation/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/atem/Data/HSE_videos/4_DLA/hw_2_SeppechSep/git_speech_separation/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/atem/Data/HSE_videos/4_DLA/hw_2_SeppechSep/git_speech_separation/.venv/lib/python3.12/site-packages/torch/nn/modules/instancenorm.py\", line 124, in forward\n",
      "    return self._apply_instance_norm(input)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/atem/Data/HSE_videos/4_DLA/hw_2_SeppechSep/git_speech_separation/.venv/lib/python3.12/site-packages/torch/nn/modules/instancenorm.py\", line 47, in _apply_instance_norm\n",
      "    return F.instance_norm(\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"/media/atem/Data/HSE_videos/4_DLA/hw_2_SeppechSep/git_speech_separation/.venv/lib/python3.12/site-packages/torch/nn/functional.py\", line 2866, in instance_norm\n",
      "    return torch.instance_norm(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 254.00 MiB. GPU 0 has a total capacity of 3.94 GiB of which 172.75 MiB is free. Process 2431274 has 282.48 MiB memory in use. Including non-PyTorch memory, this process has 1.68 GiB memory in use. Of the allocated memory 1.60 GiB is allocated by PyTorch, and 19.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "\n",
      "Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.\n",
      "Exception ignored in atexit callback: <function _MultiProcessingDataLoaderIter._clean_up_worker at 0x760678540040>\n",
      "Traceback (most recent call last):\n",
      "  File \"/media/atem/Data/HSE_videos/4_DLA/hw_2_SeppechSep/git_speech_separation/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1598, in _clean_up_worker\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/atem/.local/share/uv/python/cpython-3.12.8-linux-x86_64-gnu/lib/python3.12/multiprocessing/process.py\", line 149, in join\n",
      "    res = self._popen.wait(timeout)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/atem/.local/share/uv/python/cpython-3.12.8-linux-x86_64-gnu/lib/python3.12/multiprocessing/popen_fork.py\", line 40, in wait\n",
      "    if not wait([self.sentinel], timeout):\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/atem/.local/share/uv/python/cpython-3.12.8-linux-x86_64-gnu/lib/python3.12/multiprocessing/connection.py\", line 1136, in wait\n",
      "    ready = selector.select(timeout)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/atem/.local/share/uv/python/cpython-3.12.8-linux-x86_64-gnu/lib/python3.12/selectors.py\", line 415, in select\n",
      "    fd_event_list = self._selector.poll(timeout)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt: \n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!python3 inference.py --config-name=inference model=dttnet model_loader.from_pretrained=\"areshx/source-sep@dttnet_low_freq\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2523571",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "git_speech_separation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
